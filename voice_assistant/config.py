# voice_assistant/config.py

import os
from dotenv import load_dotenv

# Load environment variables from the .env file
load_dotenv()

class Config:
    """
    Configuration class to hold the model selection and API keys.
    
    Attributes:
        TRANSCRIPTION_MODEL (str): The model to use for transcription ('openai', 'groq', 'deepgram', 'faster-whisper', 'local').
        RESPONSE_MODEL (str): The model to use for response generation ('openai', 'groq', 'local').
        TTS_MODEL (str): The model to use for text-to-speech ('openai', 'deepgram', 'elevenlabs', 'local').
        OPENAI_API_KEY (str): API key for OpenAI services.
        GROQ_API_KEY (str): API key for Groq services.
        DEEPGRAM_API_KEY (str): API key for Deepgram services.
        ELEVENLABS_API_KEY (str): API key for ElevenLabs services.
        LOCAL_MODEL_PATH (str): Path to the local model.
    """
    # Model selection - CONFIGURED FOR RASPBERRY PI WITH OLLAMA ONLY
    TRANSCRIPTION_MODEL = 'faster-whisper'  # Local transcription
    RESPONSE_MODEL = 'ollama'  # Local LLM
    TTS_MODEL = 'piper'  # Local text-to-speech

    # Piper configuration for Raspberry Pi  
    PIPER_OUTPUT_FILE = "output.wav"
    PIPER_MODEL_PATH = "/home/pi/.local/share/piper-voices/en/en_US/lessac/medium/en_US-lessac-medium.onnx"
    PIPER_EXECUTABLE = "piper"  # Should be in PATH after installation

    # LLM Selection - MATCH YOUR INSTALLED MODEL
    OLLAMA_LLM="phi3.5:3.0b-mini-instruct-q3_k_m"  # Updated to match your installed model
    GROQ_LLM="llama3-8b-8192"  # Not used
    OPENAI_LLM="gpt-4o"  # Not used

    # Faster-Whisper Configuration - RASPBERRY PI SPEED OPTIMIZED
    FASTER_WHISPER_MODEL_SIZE = "tiny"   # Use tiny for fastest processing on Pi
    FASTER_WHISPER_DEVICE = "cpu"        # CPU only on Pi
    FASTER_WHISPER_COMPUTE_TYPE = "int8" # Keep int8 for speed and memory efficiency
    FASTER_WHISPER_CPU_THREADS = 2       # Adjust based on Pi model
    FASTER_WHISPER_NUM_WORKERS = 1       # Single worker for Pi

    # Wake Word Configuration - OPTIMIZED FOR RASPBERRY PI SPEED
    WAKE_WORD = "hi windy"
    SLEEP_WORD = "bye windy"
    WAKE_WORD_TIMEOUT = 3  # Faster timeout for wake word (was 5)
    CONVERSATION_TIMEOUT = 15  # Shorter conversation timeout for faster response (was 30)
    
    # Audio settings for wake word detection - RASPBERRY PI OPTIMIZED
    WAKE_WORD_ENERGY_THRESHOLD = 600  # Lower threshold for Pi microphones (was 800)
    WAKE_WORD_PAUSE_THRESHOLD = 0.8   # Even shorter pause for faster detection (was 1.0)

    # API keys and paths
    OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
    GROQ_API_KEY = os.getenv("GROQ_API_KEY")
    DEEPGRAM_API_KEY = os.getenv("DEEPGRAM_API_KEY")
    ELEVENLABS_API_KEY = os.getenv("ELEVENLABS_API_KEY")
    LOCAL_MODEL_PATH = os.getenv("LOCAL_MODEL_PATH")
    CARTESIA_API_KEY = os.getenv("CARTESIA_API_KEY")

    # for serving the MeloTTS model
    TTS_PORT_LOCAL = 5150

    # temp file generated by the initial STT model
    INPUT_AUDIO = "test.wav"
    
    # Wake word configuration
    WAKE_WORD = "hi windy"
    SLEEP_WORD = "bye windy" 
    WAKE_WORD_ENERGY_THRESHOLD = 800  # Lower threshold for wake word detection
    CONVERSATION_ENERGY_THRESHOLD = 1000  # Normal threshold for conversation
    
    # Response length configuration - OPTIMIZED FOR SPEED
    MAX_RESPONSE_WORDS = 15  # Shorter responses for faster speech (was 30)
    MAX_RESPONSE_TOKENS = 30  # Lower token limit for faster generation (was 60)
    RESPONSE_TEMPERATURE = 0.3  # Lower temperature for faster, more focused responses (was 0.7)

    @staticmethod
    def validate_config():
        """
        Validate the configuration to ensure all necessary environment variables are set.
        
        Raises:
            ValueError: If a required environment variable is not set.
        """
        Config._validate_model('TRANSCRIPTION_MODEL', [
            'openai', 'groq', 'deepgram', 'faster-whisper', 'local'])
        Config._validate_model('RESPONSE_MODEL', [
            'openai', 'groq', 'ollama', 'local'])
        Config._validate_model('TTS_MODEL', [
            'openai', 'deepgram', 'elevenlabs', 'melotts', 'cartesia', 'local', 'piper'])

        Config._validate_api_key('TRANSCRIPTION_MODEL', 'openai', 'OPENAI_API_KEY')
        Config._validate_api_key('TRANSCRIPTION_MODEL', 'groq', 'GROQ_API_KEY')
        Config._validate_api_key('TRANSCRIPTION_MODEL', 'deepgram', 'DEEPGRAM_API_KEY')

        Config._validate_api_key('RESPONSE_MODEL', 'openai', 'OPENAI_API_KEY')
        Config._validate_api_key('RESPONSE_MODEL', 'groq', 'GROQ_API_KEY')

        Config._validate_api_key('TTS_MODEL', 'openai', 'OPENAI_API_KEY')
        Config._validate_api_key('TTS_MODEL', 'deepgram', 'DEEPGRAM_API_KEY')
        Config._validate_api_key('TTS_MODEL', 'elevenlabs', 'ELEVENLABS_API_KEY')
        Config._validate_api_key('TTS_MODEL', 'cartesia', 'CARTESIA_API_KEY')

    @staticmethod
    def _validate_model(attribute, valid_options):
        model = getattr(Config, attribute)
        if model not in valid_options:
            raise ValueError(
                f"Invalid {attribute}. Must be one of {valid_options}"
            )
        
    @staticmethod
    def _validate_api_key(model_attr, model_value, api_key_attr):
        if getattr(Config, model_attr) == model_value and not getattr(Config, api_key_attr):
            raise ValueError(f"{api_key_attr} is required for {model_value} models")